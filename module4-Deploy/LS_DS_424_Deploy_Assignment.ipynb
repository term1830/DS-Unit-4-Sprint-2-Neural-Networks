{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Train Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Apply regularization techniques to your model. \n",
    "\n",
    "*Don't forgot to switch to GPU on Colab!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJ2b3wk62Ud"
   },
   "source": [
    "## Regularization\n",
    "\n",
    "Using your best performing model from the previous module, apply each of the following regularization strategies: \n",
    "* Early Stopping\n",
    "* Dropout\n",
    "* Weight Decay\n",
    "* Weight Constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXjs7Hk71Hy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.0) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_quickdraw10(path):\n",
    "  data = np.load(path)\n",
    "  X = data['arr_0']\n",
    "  y = data['arr_1']\n",
    "\n",
    "  print(X.shape)\n",
    "  print(y.shape)\n",
    "\n",
    "  X, y = shuffle(X, y)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  \n",
    "  return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 784)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_quickdraw10('quickdraw10.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "   1/2500 [..............................] - ETA: 0s - loss: 125.6458 - accuracy: 0.0625WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/2500 [..............................] - ETA: 1:25 - loss: 108.3840 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0688s). Check your callbacks.\n",
      "2485/2500 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.6968WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.5268 - accuracy: 0.6972 - val_loss: 0.7229 - val_accuracy: 0.7836\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 2s 943us/step - loss: 0.6592 - accuracy: 0.8008 - val_loss: 0.6649 - val_accuracy: 0.8047\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 2s 920us/step - loss: 0.5810 - accuracy: 0.8237 - val_loss: 0.5938 - val_accuracy: 0.8209\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 2s 871us/step - loss: 0.5337 - accuracy: 0.8386 - val_loss: 0.5708 - val_accuracy: 0.8320\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 2s 886us/step - loss: 0.4983 - accuracy: 0.8514 - val_loss: 0.5295 - val_accuracy: 0.8442\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 2s 873us/step - loss: 0.4686 - accuracy: 0.8592 - val_loss: 0.5568 - val_accuracy: 0.8378\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 2s 866us/step - loss: 0.4442 - accuracy: 0.8662 - val_loss: 0.5341 - val_accuracy: 0.8468\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 2s 882us/step - loss: 0.4233 - accuracy: 0.8740 - val_loss: 0.5181 - val_accuracy: 0.8508\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 2s 885us/step - loss: 0.4038 - accuracy: 0.8790 - val_loss: 0.5375 - val_accuracy: 0.8520\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 2s 876us/step - loss: 0.3896 - accuracy: 0.8831 - val_loss: 0.5025 - val_accuracy: 0.8568\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 2s 893us/step - loss: 0.3698 - accuracy: 0.8883 - val_loss: 0.5265 - val_accuracy: 0.8541\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 2s 906us/step - loss: 0.3575 - accuracy: 0.8926 - val_loss: 0.5374 - val_accuracy: 0.8553\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 2s 964us/step - loss: 0.3436 - accuracy: 0.8965 - val_loss: 0.5780 - val_accuracy: 0.8510\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 2s 975us/step - loss: 0.3321 - accuracy: 0.9000 - val_loss: 0.5599 - val_accuracy: 0.8500\n",
      "Epoch 15/100\n",
      "2500/2500 [==============================] - 2s 920us/step - loss: 0.3229 - accuracy: 0.9038 - val_loss: 0.5454 - val_accuracy: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24a67c5fa20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "###  Early stopping\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.005, patience=5)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(128),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(128),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=100, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_2_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_2_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "   2/2500 [..............................] - ETA: 1:23 - loss: 101.6680 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0648s). Check your callbacks.\n",
      "2473/2500 [============================>.] - ETA: 0s - loss: 2.2818 - accuracy: 0.5189WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_2_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 2.2696 - accuracy: 0.5206 - val_loss: 0.9707 - val_accuracy: 0.7163\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0702 - accuracy: 0.6747 - val_loss: 0.8439 - val_accuracy: 0.7487\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.9637 - accuracy: 0.7084 - val_loss: 0.7859 - val_accuracy: 0.7727\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.9037 - accuracy: 0.7266 - val_loss: 0.7502 - val_accuracy: 0.7821\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.8586 - accuracy: 0.7394 - val_loss: 0.7037 - val_accuracy: 0.7933\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.8203 - accuracy: 0.7497 - val_loss: 0.7139 - val_accuracy: 0.7925\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7980 - accuracy: 0.7612 - val_loss: 0.6701 - val_accuracy: 0.8012\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7776 - accuracy: 0.7668 - val_loss: 0.6683 - val_accuracy: 0.8055\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7659 - accuracy: 0.7714 - val_loss: 0.6814 - val_accuracy: 0.8080\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7662 - accuracy: 0.7717 - val_loss: 0.6733 - val_accuracy: 0.8043\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7470 - accuracy: 0.7770 - val_loss: 0.6471 - val_accuracy: 0.8107\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7426 - accuracy: 0.7782 - val_loss: 0.6746 - val_accuracy: 0.7973\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7344 - accuracy: 0.7830 - val_loss: 0.6748 - val_accuracy: 0.7966\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7276 - accuracy: 0.7841 - val_loss: 0.6460 - val_accuracy: 0.8129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24a6a0c7860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "## DROPOUT\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"Dropout-MaxNorm\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.005, patience=5)\n",
    "\n",
    "# Normal values tend to be between 0.2-0.5\n",
    "drop = 0.2\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128, activation='relu', kernel_constraint=MaxNorm(3)),\n",
    "    Dropout(drop),\n",
    "    Dense(128, activation='relu', kernel_constraint=MaxNorm(3)),\n",
    "    Dropout(drop),\n",
    "    Dense(128, activation='relu', kernel_constraint=MaxNorm(3)),\n",
    "    Dropout(drop),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=100, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_3_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_3_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "   2/2500 [..............................] - ETA: 1:20 - loss: 77.6419 - accuracy: 0.0938  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "2476/2500 [============================>.] - ETA: 0s - loss: 1.4962 - accuracy: 0.6979WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_3_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.4891 - accuracy: 0.6987 - val_loss: 0.7113 - val_accuracy: 0.7850\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.6440 - accuracy: 0.8047 - val_loss: 0.6096 - val_accuracy: 0.8187\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5630 - accuracy: 0.8283 - val_loss: 0.5524 - val_accuracy: 0.8366\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5152 - accuracy: 0.8437 - val_loss: 0.5370 - val_accuracy: 0.8451\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.4818 - accuracy: 0.8548 - val_loss: 0.5358 - val_accuracy: 0.8406\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.4522 - accuracy: 0.8639 - val_loss: 0.5305 - val_accuracy: 0.8482\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.4370 - accuracy: 0.8689 - val_loss: 0.5285 - val_accuracy: 0.8531\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.4197 - accuracy: 0.8739 - val_loss: 0.5292 - val_accuracy: 0.8495\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.4033 - accuracy: 0.8786 - val_loss: 0.5388 - val_accuracy: 0.8471\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3922 - accuracy: 0.8818 - val_loss: 0.5505 - val_accuracy: 0.8521\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3841 - accuracy: 0.8845 - val_loss: 0.5153 - val_accuracy: 0.8548\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3705 - accuracy: 0.8880 - val_loss: 0.5549 - val_accuracy: 0.8539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24a6c307278>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Weight constraint\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"WC-MaxNorm\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.005, patience=5)\n",
    "\n",
    "# Normal values tend to be 3-4\n",
    "wc = 3\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128, activation='relu', kernel_constraint=MaxNorm(3)),\n",
    "    Dense(128, activation='relu', kernel_constraint=MaxNorm(3)),\n",
    "    Dense(128, activation='relu', kernel_constraint=MaxNorm(3)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=100, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_4_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_4_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "   2/2500 [..............................] - ETA: 1:17 - loss: 82.7025 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0598s). Check your callbacks.\n",
      "2474/2500 [============================>.] - ETA: 0s - loss: 1.9082 - accuracy: 0.7035WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_4_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8990 - accuracy: 0.7045 - val_loss: 1.0417 - val_accuracy: 0.7888\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.9450 - accuracy: 0.8008 - val_loss: 0.8566 - val_accuracy: 0.8141\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7596 - accuracy: 0.8263 - val_loss: 0.7242 - val_accuracy: 0.8292\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.6567 - accuracy: 0.8386 - val_loss: 0.6782 - val_accuracy: 0.8336\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.6179 - accuracy: 0.8470 - val_loss: 0.6302 - val_accuracy: 0.8454\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5986 - accuracy: 0.8519 - val_loss: 0.6402 - val_accuracy: 0.8439\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5849 - accuracy: 0.8563 - val_loss: 0.6324 - val_accuracy: 0.8493\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5781 - accuracy: 0.8588 - val_loss: 0.6381 - val_accuracy: 0.8395\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5716 - accuracy: 0.8606 - val_loss: 0.6126 - val_accuracy: 0.8524\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.8625 - val_loss: 0.6141 - val_accuracy: 0.8475\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5607 - accuracy: 0.8658 - val_loss: 0.6161 - val_accuracy: 0.8482\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5592 - accuracy: 0.8658 - val_loss: 0.6063 - val_accuracy: 0.8549\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5571 - accuracy: 0.8664 - val_loss: 0.6208 - val_accuracy: 0.8498\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5546 - accuracy: 0.8681 - val_loss: 0.6241 - val_accuracy: 0.8480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24a414e58d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "#weight decay\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"L2-weight decay\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.005, patience=5)\n",
    "\n",
    "# Normal values tend to be 0 to 0.0001 on log scale\n",
    "wd = 0.001\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.L2(wd)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.L2(wd)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.L2(wd)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=100, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pScpa3nRRxCN"
   },
   "source": [
    "## Deploy\n",
    "\n",
    "Save your model's weights using the Checkpoint function. Try reloading the model and making inference on your validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cqpHQt_SIbW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_6_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_6_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "2484/2500 [============================>.] - ETA: 0s - loss: 1.4770 - accuracy: 0.7105WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_6_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78765, saving model to best_weights.h5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.4719 - accuracy: 0.7109 - val_loss: 0.6828 - val_accuracy: 0.7876\n",
      "Epoch 2/100\n",
      "2471/2500 [============================>.] - ETA: 0s - loss: 0.6284 - accuracy: 0.8074\n",
      "Epoch 00002: val_accuracy improved from 0.78765 to 0.81550, saving model to best_weights.h5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.6279 - accuracy: 0.8076 - val_loss: 0.6067 - val_accuracy: 0.8155\n",
      "Epoch 3/100\n",
      "2490/2500 [============================>.] - ETA: 0s - loss: 0.5579 - accuracy: 0.8309\n",
      "Epoch 00003: val_accuracy improved from 0.81550 to 0.83340, saving model to best_weights.h5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5579 - accuracy: 0.8310 - val_loss: 0.5599 - val_accuracy: 0.8334\n",
      "Epoch 4/100\n",
      "2459/2500 [============================>.] - ETA: 0s - loss: 0.5110 - accuracy: 0.8460\n",
      "Epoch 00004: val_accuracy improved from 0.83340 to 0.84135, saving model to best_weights.h5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.5105 - accuracy: 0.8460 - val_loss: 0.5459 - val_accuracy: 0.8414\n",
      "Epoch 5/100\n",
      "2481/2500 [============================>.] - ETA: 0s - loss: 0.4719 - accuracy: 0.8587\n",
      "Epoch 00005: val_accuracy improved from 0.84135 to 0.84915, saving model to best_weights.h5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.4720 - accuracy: 0.8586 - val_loss: 0.5165 - val_accuracy: 0.8492\n",
      "Epoch 6/100\n",
      "2464/2500 [============================>.] - ETA: 0s - loss: 0.4355 - accuracy: 0.8674\n",
      "Epoch 00006: val_accuracy improved from 0.84915 to 0.85100, saving model to best_weights.h5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.4359 - accuracy: 0.8674 - val_loss: 0.5063 - val_accuracy: 0.8510\n",
      "Epoch 7/100\n",
      "2482/2500 [============================>.] - ETA: 0s - loss: 0.4084 - accuracy: 0.8766\n",
      "Epoch 00007: val_accuracy improved from 0.85100 to 0.85500, saving model to best_weights.h5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.4082 - accuracy: 0.8765 - val_loss: 0.4980 - val_accuracy: 0.8550\n",
      "Epoch 8/100\n",
      "2460/2500 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8835\n",
      "Epoch 00008: val_accuracy improved from 0.85500 to 0.85935, saving model to best_weights.h5\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3842 - accuracy: 0.8834 - val_loss: 0.5039 - val_accuracy: 0.8594\n",
      "Epoch 9/100\n",
      "2470/2500 [============================>.] - ETA: 0s - loss: 0.3614 - accuracy: 0.8900\n",
      "Epoch 00009: val_accuracy did not improve from 0.85935\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3618 - accuracy: 0.8898 - val_loss: 0.5341 - val_accuracy: 0.8529\n",
      "Epoch 10/100\n",
      "2460/2500 [============================>.] - ETA: 0s - loss: 0.3451 - accuracy: 0.8953\n",
      "Epoch 00010: val_accuracy did not improve from 0.85935\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3455 - accuracy: 0.8952 - val_loss: 0.5361 - val_accuracy: 0.8579\n",
      "Epoch 11/100\n",
      "2481/2500 [============================>.] - ETA: 0s - loss: 0.3281 - accuracy: 0.9001\n",
      "Epoch 00011: val_accuracy did not improve from 0.85935\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3285 - accuracy: 0.9000 - val_loss: 0.5843 - val_accuracy: 0.8479\n",
      "Epoch 12/100\n",
      "2454/2500 [============================>.] - ETA: 0s - loss: 0.3143 - accuracy: 0.9043\n",
      "Epoch 00012: val_accuracy did not improve from 0.85935\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3146 - accuracy: 0.9043 - val_loss: 0.5631 - val_accuracy: 0.8550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24a42740320>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.005, patience=5)\n",
    "mcp = ModelCheckpoint('best_weights.h5', \n",
    "                      monitor='val_accuracy', \n",
    "                      verbose=1, \n",
    "                      save_best_only=True,\n",
    "                      save_weights_only=True)\n",
    "\n",
    "def get_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        Flatten(input_shape=(28,28)),\n",
    "        Dense(128, activation='relu'),\n",
    "        ReLU(negative_slope=.01),\n",
    "        Dense(128),\n",
    "        ReLU(negative_slope=.01),\n",
    "        Dense(128),\n",
    "        ReLU(negative_slope=.01),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=100, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[stop, mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 394us/step - loss: 0.5039 - accuracy: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5039432644844055, 0.8593500256538391]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('best_weights.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_7_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_7_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "625/625 [==============================] - 0s 697us/step - loss: 0.5039 - accuracy: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5039432644844055, 0.8593500256538391]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = get_model()\n",
    "model2.load_weights('best_weights.h5')\n",
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKbr1gRg9BXs"
   },
   "source": [
    "### Stretch Goals\n",
    "- Mount your Google Drive to Colab to persist your model checkpoint files. \n",
    "- Research L2 normalization (weight decay)\n",
    "- Write a custom callback function to stop training after you reach .88 validation accuracy. \n",
    "- Select a new dataset and apply a neural network to it.\n",
    "- Research TensorFlow Serving\n",
    "- Play [QuickDraw](https://quickdraw.withgoogle.com/data)\n",
    "- Create a static webpage using TensorFlow.js to serve a model. Check out [Teachable Machine Learning](https://teachablemachine.withgoogle.com/) for ideas. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_434_Deploy_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "U4-S2-NN",
   "language": "python",
   "name": "u4-s2-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
