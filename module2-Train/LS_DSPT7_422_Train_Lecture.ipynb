{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DSPT7_422_Train_Lecture.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS4GZ37Wgcjr"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 2, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etFf1WLWgcjt",
        "toc-hr-collapsed": false
      },
      "source": [
        "# Train (Prepare)\n",
        "__*Neural Network Foundations*__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXB80QOhgcju"
      },
      "source": [
        "## Learning Objectives\n",
        "* <a href=\"#p1\">Part 1</a>: Student should be able to explain the intuition behind backpropagation and gradient descent\n",
        "* <a href=\"#p2\">Part 2</a>: Student should be able to discuss the importance of batch size\n",
        "* <a href=\"#p3\">Part 3</a>: Student should be able to discuss the importance of learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YuQu2lfgcju"
      },
      "source": [
        "## Summary of Yesterday\n",
        "\n",
        "Yesterday, we learned about some of the principal components of Neural Networks: Neurons, Weights, Activation Functions, and layers (input, output, & hidden). Today, we will reinforce our understanding of those components and introduce the mechanics of training a neural network. Feed-forward neural networks, such as multi-layer perceptrons (MLPs), are almost always trained using some variation of gradient descent where the gradient has been calculated by backpropagation.\n",
        "\n",
        "  <center><img src=\"https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/main/module1-Architect/IMG_0167.jpeg\" width=400></center>\n",
        "\n",
        "- There are three kinds of layers: input, hidden, and output layers.\n",
        "- Each layer is made up of **n** individual neurons (aka activation units) which have a corresponding weight and bias.\n",
        "- Signal is passed from layer to layer through a network by:\n",
        " - Taking in inputs from the training data (or previous layer)\n",
        " - Multiplying each input by its corresponding weight (think arrow/connecting line)\n",
        " - Adding a bias to this weighted some of inputs and weights\n",
        " - Activating this weighted sum + bias by squishifying it with sigmoid or some other activation function. With a single perceptron with three inputs, calculating the output from the node is done like so:\n",
        "\\begin{align}\n",
        " y = sigmoid(\\sum(weight_{1}input_{1} + weight_{2}input_{2} + weight_{3}input_{3}) + bias)\n",
        "\\end{align}\n",
        " - this final activated value is the signal that gets passed onto the next layer of the network.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpi4R03rgcjv"
      },
      "source": [
        "## Training a Neural Network: *Formal Summary*\n",
        "\n",
        "0. Pick a network architecture\n",
        "   - No. of input units = No. of features\n",
        "   - No. of output units = Number of Classes (or expected targets)\n",
        "   - Select the number of hidden layers and number of neurons within each hidden layer\n",
        "1. Randomly initialize weights\n",
        "2. Implement forward propagation to get $h_{\\theta}(x^{(i)})$ for any $x^{(i)}$\n",
        "3. Implement code to compute a cost function $J(\\theta)$\n",
        "4. Implement backpropagation to compute partial derivatives $\\frac{\\delta}{\\delta\\theta_{jk}^{l}}{J(\\theta)}$\n",
        "5. Use gradient descent (or other advanced optimizer) with backpropagation to minimize $J(\\theta)$ as a function of parameters $\\theta\\$\n",
        "6. Repeat steps 2 - 5 until cost function is 'minimized' or some other stopping criteria is met. One pass over steps 2 - 5 is called an iteration or epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM4CK1IarId4",
        "toc-hr-collapsed": false
      },
      "source": [
        "# Backpropagation & Gradient Descent (Learn)\n",
        "<a id=\"p1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ktm8Fmoagcjy",
        "toc-hr-collapsed": true
      },
      "source": [
        "## Overview\n",
        "\n",
        "Backpropagation is short for [\"Backwards Propagation of errors\"](https://en.wikipedia.org/wiki/Backpropagation) and refers to a specific (rather calculus intensive) algorithm for how weights in a neural network are updated in reverse order at the end of each training epoch. Our purpose today is to demonstrate the backpropagation algorithm on a simple Feedforward Neural Network and in so doing help you get a grasp on the main process. If you want to understand all of the underlying calculus of how the gradients are calculated then you'll need to dive into it yourself, [3Blue1Brown's video is a great starting place](https://www.youtube.com/watch?v=tIeHLnjs5U8). I also highly recommend this Welch Labs series [Neural Networks Demystified](https://www.youtube.com/watch?v=bxe2T-V8XRs) if you want a rapid yet orderly walk through of the main intuitions and math behind the backpropagation algorithm. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXI2tEO9gcjy"
      },
      "source": [
        "### What is a Gradient?\n",
        "\n",
        "> In vector calculus, the gradient is a multi-variable generalization of the derivative. \n",
        "\n",
        "The gradients that we will deal with today will be vector representations of the derivative of the activation function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZY66kiUgcjz",
        "toc-hr-collapsed": true
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "In this section, we will again a simple neural network using base TensorFlow. We'll focus on using a __Feed Forward Neural Network__ to predict test scores. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm2HPETcrgy6",
        "toc-hr-collapsed": true
      },
      "source": [
        "<center><img src=\"https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/main/module1-Architect/IMG_99C94113202D-1.jpeg\"width=500></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d4tzpwO6B47"
      },
      "source": [
        "### Generate some Fake Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERyVgeO_IWyV"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Imagine that our data is drawn from a linear function\n",
        "# y = 3.5*hours_studying + 50\n",
        "\n",
        "TRUE_W = 3.5\n",
        "TRUE_b = 50.0\n",
        "NUM_EXAMPLES = 1000\n",
        "\n",
        "inputs = tf.random.normal(shape=[NUM_EXAMPLES])\n",
        "noise = tf.random.normal(shape=[NUM_EXAMPLES])\n",
        "\n",
        "outputs = inputs * TRUE_W + TRUE_b + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCJesGEUgcj4"
      },
      "source": [
        "### Loss Function\n",
        "Here we will use Mean Squared Error (MSE), because this is a regression problem. We are trying to predict a continuous target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDeUBW6k4Ri4"
      },
      "source": [
        "def loss(target_y, predicted_y):\n",
        "  \"MSE\"\n",
        "  return tf.reduce_mean(tf.square(target_y - predicted_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgTf6vTS69Sw"
      },
      "source": [
        "### Neural Network Architecture\n",
        "Lets create a Neural Network class called \"Model\" to contain this functionality. Note: This is essentially a linear regression whose coefficients are trained by gradient descent. In practice, gradient descent works on much more complex function like the multi-layer networks we constructed yesterday."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUI8VSR5zyBv"
      },
      "source": [
        "class Model(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.W = tf.Variable(10.0)\n",
        "    self.b = tf.Variable(20.0)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.W * x + self.b\n",
        "\n",
        "model = Model()\n",
        "\n",
        "# assert model(3.0).numpy() == 64.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbyT_FJ88IlK"
      },
      "source": [
        "### Initial Weights\n",
        "The initial weights in our model were arbitrary. In practice, weights are initialized randomly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IreIDe6P8H0H",
        "outputId": "696c0cfb-f971-41cd-831a-0a7b85f71111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(inputs, outputs, c='b')\n",
        "plt.scatter(inputs, model(inputs), c='r')\n",
        "plt.show()\n",
        "\n",
        "print('Current loss: %1.6f' % loss(model(inputs), outputs).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Current loss: 942.039246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16Ujj6vNYQyX",
        "toc-hr-collapsed": true
      },
      "source": [
        "### Update Weights Based on Gradient\n",
        "\n",
        "> *Assigning blame for bad predictions and delivering justice - repeatedly and a little bit at a time*\n",
        "\n",
        "You should also know that with neural networks it is common to have gradients that are not convex (like what we saw when we applied gradient descent to linear regression). \n",
        "\n",
        "Due to the high complexity of these models and their nonlinearity, it is common for gradient descent to get stuck in a local minimum, but there are ways to combat this:\n",
        "\n",
        "1) Stochastic Gradient Descent\n",
        "\n",
        "2) More advanced Gradient-Descent-based \"Optimizers\" - See Stretch Goals on assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgaGD6YlHoid"
      },
      "source": [
        " def train(model, inputs, outputs, learning_rate):\n",
        "  with tf.GradientTape() as t: \n",
        "     current_loss = loss(outputs, model(inputs))\n",
        "  dW, db = t.gradient(current_loss, [model.W, model.b])\n",
        "  model.W.assign_sub(learning_rate * dW)\n",
        "  model.b.assign_sub(learning_rate * db)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iziWWURgck8"
      },
      "source": [
        "### Train the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zn_HgFuHhTr",
        "outputId": "3c6f9ca8-b96e-4987-ad58-bf239d678067",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Model()\n",
        "\n",
        "# Store Some history of weights\n",
        "Ws, bs = [], []\n",
        "epochs = range(25)\n",
        "for epoch in epochs:\n",
        "  Ws.append(model.W.numpy())\n",
        "  bs.append(model.b.numpy())\n",
        "  current_loss = loss(outputs, model(inputs))\n",
        "\n",
        "  train(model, inputs, outputs, learning_rate=0.1)\n",
        "  print('Epoch %2d: W=%1.2f b=%1.2f loss=%2.5f' % (epoch, Ws[-1], bs[-1], current_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0: W=10.00 b=20.00 loss=942.03925\n",
            "Epoch  1: W=8.75 b=26.00 loss=604.17657\n",
            "Epoch  2: W=7.74 b=30.80 loss=387.62399\n",
            "Epoch  3: W=6.92 b=34.64 loss=248.82329\n",
            "Epoch  4: W=6.27 b=37.71 loss=159.85709\n",
            "Epoch  5: W=5.73 b=40.17 loss=102.83217\n",
            "Epoch  6: W=5.31 b=42.14 loss=66.28036\n",
            "Epoch  7: W=4.96 b=43.72 loss=42.85114\n",
            "Epoch  8: W=4.68 b=44.98 loss=27.83311\n",
            "Epoch  9: W=4.46 b=45.99 loss=18.20648\n",
            "Epoch 10: W=4.27 b=46.79 loss=12.03570\n",
            "Epoch 11: W=4.13 b=47.44 loss=8.08011\n",
            "Epoch 12: W=4.01 b=47.96 loss=5.54449\n",
            "Epoch 13: W=3.91 b=48.37 loss=3.91905\n",
            "Epoch 14: W=3.84 b=48.70 loss=2.87708\n",
            "Epoch 15: W=3.77 b=48.97 loss=2.20913\n",
            "Epoch 16: W=3.72 b=49.18 loss=1.78093\n",
            "Epoch 17: W=3.68 b=49.35 loss=1.50643\n",
            "Epoch 18: W=3.65 b=49.49 loss=1.33045\n",
            "Epoch 19: W=3.62 b=49.59 loss=1.21764\n",
            "Epoch 20: W=3.60 b=49.68 loss=1.14532\n",
            "Epoch 21: W=3.59 b=49.75 loss=1.09895\n",
            "Epoch 22: W=3.57 b=49.81 loss=1.06922\n",
            "Epoch 23: W=3.56 b=49.85 loss=1.05017\n",
            "Epoch 24: W=3.55 b=49.89 loss=1.03795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSEt07wdHvi2",
        "outputId": "b8316dc5-a6f6-40fe-801e-d04cf280dbcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epochs, Ws, 'r', epochs, bs, 'b')\n",
        "plt.plot([TRUE_W] * len(epochs), 'r--',\n",
        "         [TRUE_b] * len(epochs), 'b--')\n",
        "plt.legend(['W', 'b', 'True W', 'True b'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKUVGoRxgck_"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "In the module project, you will be asked to explain the logic of backpropagation and gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRsjONxQemmp"
      },
      "source": [
        "### In the following two sections we'll look at batch size and learning rate hyperparameters in isolation. \n",
        "However, it's important to know that recent research found some interesting relationships between batch sizes and learning rates. The best available suggestion today is to scale batch size proportionally to a learning rate:\n",
        "- https://openreview.net/pdf?id=B1Yy1BxCZ\n",
        "- https://papers.nips.cc/paper/8398-control-batch-size-and-learning-rate-to-generalize-well-theoretical-and-empirical-evidence.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTqZg-6igclA",
        "toc-hr-collapsed": true
      },
      "source": [
        "# Batch Size (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nrm-racgclA"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The What - Stochastic Gradient Descent calculates an approximation of the gradient over the entire dataset by reviewing the predictions of a random sample. \n",
        "\n",
        "The Why - *Speed*. Calculating the gradient over the entire dataset is extremely expensive computationally. \n",
        "\n",
        "### Batch Size\n",
        "Batches are the number of observations our model is shown to make predictions and update the weights. Batches are selected randomly during epoch. All observations are considered when passing thru an epoch at some point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNQ2ZCi7I4i6"
      },
      "source": [
        "### Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZjW2lYVI9Q2",
        "outputId": "07a0eb0e-4922-47cf-98ec-c3a7fc0cbcea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test / 255.\n",
        "\n",
        "X_train = X_train.reshape((60000, 784))\n",
        "X_test = X_test.reshape((10000, 784))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7x17kDKJSy5"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "def create_model(lr=0.01):\n",
        "  opt = SGD(learning_rate=lr)\n",
        "  model = Sequential([\n",
        "    Dense(32, activation='relu', input_dim=784),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7UE-KluPsX"
      },
      "source": [
        "## Follow Along\n",
        "Let's run a series of experiments for a default, small, and large batch size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhpDaVFRJl3U"
      },
      "source": [
        "### Default\n",
        "Batch Size is 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-ChVGikgclD",
        "outputId": "efdcf0a9-d1fc-4c77-b025-a2f8e3da9569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 26,506\n",
            "Trainable params: 26,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0P6CPYiz6eH",
        "outputId": "fd263b31-8757-4645-d87c-8adc0a165dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(784 + 1) * 32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwhohGsh0H4K",
        "outputId": "610a18ec-81bb-4e78-e676-9535846bd901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(32 + 1) * 32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU1Epv6f1f_o",
        "outputId": "5815907f-aa65-42df-f491-06a11b1b89ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bt_default = model.fit(\n",
        "  X_train, y_train,\n",
        "  epochs=25,\n",
        "  batch_size=32,\n",
        "  validation_data=(X_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7447 - accuracy: 0.7938 - val_loss: 0.3654 - val_accuracy: 0.8957\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3312 - accuracy: 0.9047 - val_loss: 0.2885 - val_accuracy: 0.9191\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2780 - accuracy: 0.9192 - val_loss: 0.2520 - val_accuracy: 0.9292\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2477 - accuracy: 0.9281 - val_loss: 0.2329 - val_accuracy: 0.9344\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2239 - accuracy: 0.9349 - val_loss: 0.2111 - val_accuracy: 0.9406\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2048 - accuracy: 0.9405 - val_loss: 0.1937 - val_accuracy: 0.9435\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1890 - accuracy: 0.9456 - val_loss: 0.1846 - val_accuracy: 0.9450\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1758 - accuracy: 0.9482 - val_loss: 0.1747 - val_accuracy: 0.9492\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1641 - accuracy: 0.9520 - val_loss: 0.1629 - val_accuracy: 0.9525\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1544 - accuracy: 0.9543 - val_loss: 0.1559 - val_accuracy: 0.9511\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1459 - accuracy: 0.9568 - val_loss: 0.1485 - val_accuracy: 0.9559\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1383 - accuracy: 0.9596 - val_loss: 0.1495 - val_accuracy: 0.9542\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1316 - accuracy: 0.9610 - val_loss: 0.1390 - val_accuracy: 0.9581\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1258 - accuracy: 0.9629 - val_loss: 0.1376 - val_accuracy: 0.9592\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1204 - accuracy: 0.9643 - val_loss: 0.1345 - val_accuracy: 0.9593\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1161 - accuracy: 0.9655 - val_loss: 0.1307 - val_accuracy: 0.9610\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1114 - accuracy: 0.9675 - val_loss: 0.1272 - val_accuracy: 0.9620\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1074 - accuracy: 0.9681 - val_loss: 0.1236 - val_accuracy: 0.9624\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1035 - accuracy: 0.9694 - val_loss: 0.1230 - val_accuracy: 0.9622\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1001 - accuracy: 0.9703 - val_loss: 0.1273 - val_accuracy: 0.9615\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0968 - accuracy: 0.9712 - val_loss: 0.1202 - val_accuracy: 0.9645\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0934 - accuracy: 0.9721 - val_loss: 0.1172 - val_accuracy: 0.9633\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0911 - accuracy: 0.9729 - val_loss: 0.1167 - val_accuracy: 0.9645\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0881 - accuracy: 0.9742 - val_loss: 0.1150 - val_accuracy: 0.9645\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0858 - accuracy: 0.9744 - val_loss: 0.1163 - val_accuracy: 0.9649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fc0N9qF1xXe",
        "outputId": "6f3b64e6-43b3-4301-f609-6ac36b75ae5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "1875*32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvsbOFnDJuG0"
      },
      "source": [
        "### Small Batch Size\n",
        "Batch Size is 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diDzvb-UJ1je",
        "outputId": "bac54666-ed05-4479-8746-ee3003d8e872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "bt_small = model.fit(\n",
        "  X_train, y_train,\n",
        "  epochs=25,\n",
        "  batch_size=8,\n",
        "  validation_data=(X_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.4302 - accuracy: 0.8738 - val_loss: 0.2486 - val_accuracy: 0.9239\n",
            "Epoch 2/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.2152 - accuracy: 0.9372 - val_loss: 0.1759 - val_accuracy: 0.9473\n",
            "Epoch 3/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.1680 - accuracy: 0.9502 - val_loss: 0.1499 - val_accuracy: 0.9548\n",
            "Epoch 4/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.1419 - accuracy: 0.9577 - val_loss: 0.1483 - val_accuracy: 0.9553\n",
            "Epoch 5/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.1250 - accuracy: 0.9629 - val_loss: 0.1311 - val_accuracy: 0.9615\n",
            "Epoch 6/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.1145 - accuracy: 0.9657 - val_loss: 0.1178 - val_accuracy: 0.9660\n",
            "Epoch 7/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.1044 - accuracy: 0.9683 - val_loss: 0.1164 - val_accuracy: 0.9661\n",
            "Epoch 8/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0966 - accuracy: 0.9706 - val_loss: 0.1299 - val_accuracy: 0.9614\n",
            "Epoch 9/25\n",
            "7500/7500 [==============================] - 22s 3ms/step - loss: 0.0890 - accuracy: 0.9736 - val_loss: 0.1089 - val_accuracy: 0.9682\n",
            "Epoch 10/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0838 - accuracy: 0.9744 - val_loss: 0.1111 - val_accuracy: 0.9677\n",
            "Epoch 11/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0775 - accuracy: 0.9765 - val_loss: 0.1153 - val_accuracy: 0.9658\n",
            "Epoch 12/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0736 - accuracy: 0.9777 - val_loss: 0.1097 - val_accuracy: 0.9678\n",
            "Epoch 13/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0694 - accuracy: 0.9786 - val_loss: 0.1222 - val_accuracy: 0.9657\n",
            "Epoch 14/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0647 - accuracy: 0.9803 - val_loss: 0.1071 - val_accuracy: 0.9698\n",
            "Epoch 15/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0616 - accuracy: 0.9811 - val_loss: 0.1103 - val_accuracy: 0.9680\n",
            "Epoch 16/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0592 - accuracy: 0.9823 - val_loss: 0.1072 - val_accuracy: 0.9688\n",
            "Epoch 17/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0557 - accuracy: 0.9829 - val_loss: 0.1124 - val_accuracy: 0.9701\n",
            "Epoch 18/25\n",
            "7500/7500 [==============================] - 21s 3ms/step - loss: 0.0537 - accuracy: 0.9827 - val_loss: 0.1116 - val_accuracy: 0.9681\n",
            "Epoch 19/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.1058 - val_accuracy: 0.9703\n",
            "Epoch 20/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.1260 - val_accuracy: 0.9661\n",
            "Epoch 21/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0464 - accuracy: 0.9856 - val_loss: 0.1098 - val_accuracy: 0.9699\n",
            "Epoch 22/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0432 - accuracy: 0.9865 - val_loss: 0.1099 - val_accuracy: 0.9718\n",
            "Epoch 23/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0428 - accuracy: 0.9865 - val_loss: 0.1155 - val_accuracy: 0.9681\n",
            "Epoch 24/25\n",
            "7500/7500 [==============================] - 22s 3ms/step - loss: 0.0401 - accuracy: 0.9874 - val_loss: 0.1175 - val_accuracy: 0.9707\n",
            "Epoch 25/25\n",
            "7500/7500 [==============================] - 20s 3ms/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 0.1127 - val_accuracy: 0.9709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iPvvvt5J2Xl"
      },
      "source": [
        "### Large Batch Size\n",
        "Batch Size is 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h8Z5293KABT",
        "outputId": "9bd8226c-a835-435d-8444-65e74624c383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "bt_big = model.fit(\n",
        "  X_train, y_train,\n",
        "  epochs=25,\n",
        "  batch_size=512,\n",
        "  validation_data=(X_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.1805 - accuracy: 0.2149 - val_loss: 1.9751 - val_accuracy: 0.4121\n",
            "Epoch 2/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.7126 - accuracy: 0.5881 - val_loss: 1.4094 - val_accuracy: 0.6916\n",
            "Epoch 3/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.1848 - accuracy: 0.7413 - val_loss: 0.9726 - val_accuracy: 0.7828\n",
            "Epoch 4/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8627 - accuracy: 0.8023 - val_loss: 0.7438 - val_accuracy: 0.8273\n",
            "Epoch 5/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.8311 - val_loss: 0.6178 - val_accuracy: 0.8463\n",
            "Epoch 6/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.5942 - accuracy: 0.8484 - val_loss: 0.5426 - val_accuracy: 0.8578\n",
            "Epoch 7/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.5314 - accuracy: 0.8606 - val_loss: 0.4894 - val_accuracy: 0.8684\n",
            "Epoch 8/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.8689 - val_loss: 0.4535 - val_accuracy: 0.8754\n",
            "Epoch 9/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.8758 - val_loss: 0.4268 - val_accuracy: 0.8809\n",
            "Epoch 10/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8810 - val_loss: 0.4056 - val_accuracy: 0.8854\n",
            "Epoch 11/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.4136 - accuracy: 0.8851 - val_loss: 0.3888 - val_accuracy: 0.8884\n",
            "Epoch 12/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3984 - accuracy: 0.8887 - val_loss: 0.3756 - val_accuracy: 0.8924\n",
            "Epoch 13/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8916 - val_loss: 0.3653 - val_accuracy: 0.8958\n",
            "Epoch 14/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3751 - accuracy: 0.8943 - val_loss: 0.3551 - val_accuracy: 0.8982\n",
            "Epoch 15/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8967 - val_loss: 0.3468 - val_accuracy: 0.9011\n",
            "Epoch 16/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8987 - val_loss: 0.3391 - val_accuracy: 0.9038\n",
            "Epoch 17/25\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.9007 - val_loss: 0.3328 - val_accuracy: 0.9044\n",
            "Epoch 18/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.9024 - val_loss: 0.3274 - val_accuracy: 0.9066\n",
            "Epoch 19/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.9039 - val_loss: 0.3221 - val_accuracy: 0.9093\n",
            "Epoch 20/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.9053 - val_loss: 0.3167 - val_accuracy: 0.9104\n",
            "Epoch 21/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3280 - accuracy: 0.9066 - val_loss: 0.3127 - val_accuracy: 0.9112\n",
            "Epoch 22/25\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3234 - accuracy: 0.9078 - val_loss: 0.3086 - val_accuracy: 0.9127\n",
            "Epoch 23/25\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3191 - accuracy: 0.9092 - val_loss: 0.3044 - val_accuracy: 0.9134\n",
            "Epoch 24/25\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3150 - accuracy: 0.9101 - val_loss: 0.3013 - val_accuracy: 0.9147\n",
            "Epoch 25/25\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3112 - accuracy: 0.9111 - val_loss: 0.2977 - val_accuracy: 0.9155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SEqu04m6DRh",
        "outputId": "d97ff849-2fc3-4d00-b17e-f435532322f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bt_big.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.2149166613817215,\n",
              "  0.5880500078201294,\n",
              "  0.741266667842865,\n",
              "  0.8023499846458435,\n",
              "  0.831083357334137,\n",
              "  0.8483666777610779,\n",
              "  0.8606166839599609,\n",
              "  0.8689166903495789,\n",
              "  0.8757500052452087,\n",
              "  0.8810166716575623,\n",
              "  0.8850666880607605,\n",
              "  0.888700008392334,\n",
              "  0.8915833234786987,\n",
              "  0.8943333625793457,\n",
              "  0.8967000246047974,\n",
              "  0.8986999988555908,\n",
              "  0.9006833434104919,\n",
              "  0.9023666381835938,\n",
              "  0.9039000272750854,\n",
              "  0.9053166508674622,\n",
              "  0.906583309173584,\n",
              "  0.9078333377838135,\n",
              "  0.9091500043869019,\n",
              "  0.9101499915122986,\n",
              "  0.9110666513442993],\n",
              " 'loss': [2.1805357933044434,\n",
              "  1.712646484375,\n",
              "  1.184794306755066,\n",
              "  0.8627088069915771,\n",
              "  0.6926453113555908,\n",
              "  0.5941837430000305,\n",
              "  0.5314193964004517,\n",
              "  0.4880029857158661,\n",
              "  0.45650118589401245,\n",
              "  0.4326690435409546,\n",
              "  0.4136488139629364,\n",
              "  0.39841803908348083,\n",
              "  0.3858218193054199,\n",
              "  0.3751322627067566,\n",
              "  0.365762323141098,\n",
              "  0.35783085227012634,\n",
              "  0.3506366014480591,\n",
              "  0.3442334830760956,\n",
              "  0.3383035659790039,\n",
              "  0.33299821615219116,\n",
              "  0.3279604911804199,\n",
              "  0.3234230875968933,\n",
              "  0.3190765380859375,\n",
              "  0.31501489877700806,\n",
              "  0.31118276715278625],\n",
              " 'val_accuracy': [0.4120999872684479,\n",
              "  0.6916000247001648,\n",
              "  0.782800018787384,\n",
              "  0.8273000121116638,\n",
              "  0.8463000059127808,\n",
              "  0.8578000068664551,\n",
              "  0.868399977684021,\n",
              "  0.8754000067710876,\n",
              "  0.8809000253677368,\n",
              "  0.8853999972343445,\n",
              "  0.8884000182151794,\n",
              "  0.8924000263214111,\n",
              "  0.895799994468689,\n",
              "  0.8981999754905701,\n",
              "  0.9010999798774719,\n",
              "  0.9038000106811523,\n",
              "  0.9043999910354614,\n",
              "  0.9065999984741211,\n",
              "  0.9093000292778015,\n",
              "  0.9103999733924866,\n",
              "  0.9111999869346619,\n",
              "  0.9126999974250793,\n",
              "  0.9133999943733215,\n",
              "  0.9146999716758728,\n",
              "  0.9154999852180481],\n",
              " 'val_loss': [1.9750930070877075,\n",
              "  1.4093834161758423,\n",
              "  0.9726346731185913,\n",
              "  0.7438145279884338,\n",
              "  0.6177933812141418,\n",
              "  0.5426101684570312,\n",
              "  0.48944711685180664,\n",
              "  0.4535316526889801,\n",
              "  0.42683589458465576,\n",
              "  0.4055868089199066,\n",
              "  0.388805091381073,\n",
              "  0.3755718469619751,\n",
              "  0.3652859628200531,\n",
              "  0.35514235496520996,\n",
              "  0.34680357575416565,\n",
              "  0.33908411860466003,\n",
              "  0.3328334093093872,\n",
              "  0.32735639810562134,\n",
              "  0.32212042808532715,\n",
              "  0.3166738450527191,\n",
              "  0.312724232673645,\n",
              "  0.3085709810256958,\n",
              "  0.3043767213821411,\n",
              "  0.3012797236442566,\n",
              "  0.2976911664009094]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0ujUz6BKUGz"
      },
      "source": [
        "### Visualization of Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-5DOZNMKYt-",
        "outputId": "a519f7fb-0fda-4e8a-8346-e2ebd4b5ec37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "batch_sizes = []\n",
        "\n",
        "for exp, result in zip([bt_default, bt_small, bt_big], [\"32_\", \"8_\", \"512_\"]):\n",
        "    df = pd.DataFrame.from_dict(exp.history)\n",
        "    df['epoch'] = df.index.values\n",
        "    df['Batch Size'] = result\n",
        "    batch_sizes.append(df)\n",
        "\n",
        "df = pd.concat(batch_sizes)\n",
        "df['Batch Size'] = df['Batch Size'].astype('str')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "      <th>Batch Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.744670</td>\n",
              "      <td>0.793800</td>\n",
              "      <td>0.365359</td>\n",
              "      <td>0.8957</td>\n",
              "      <td>0</td>\n",
              "      <td>32_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.331163</td>\n",
              "      <td>0.904700</td>\n",
              "      <td>0.288484</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>1</td>\n",
              "      <td>32_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.278024</td>\n",
              "      <td>0.919167</td>\n",
              "      <td>0.252035</td>\n",
              "      <td>0.9292</td>\n",
              "      <td>2</td>\n",
              "      <td>32_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.247724</td>\n",
              "      <td>0.928067</td>\n",
              "      <td>0.232938</td>\n",
              "      <td>0.9344</td>\n",
              "      <td>3</td>\n",
              "      <td>32_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.223893</td>\n",
              "      <td>0.934917</td>\n",
              "      <td>0.211148</td>\n",
              "      <td>0.9406</td>\n",
              "      <td>4</td>\n",
              "      <td>32_</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy  epoch Batch Size\n",
              "0  0.744670  0.793800  0.365359        0.8957      0        32_\n",
              "1  0.331163  0.904700  0.288484        0.9191      1        32_\n",
              "2  0.278024  0.919167  0.252035        0.9292      2        32_\n",
              "3  0.247724  0.928067  0.232938        0.9344      3        32_\n",
              "4  0.223893  0.934917  0.211148        0.9406      4        32_"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3ecm1Cc6Olt",
        "outputId": "8fcb6489-3fbe-47ec-fe92-94cfd53ba218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "sns.lineplot(x='epoch', y='val_accuracy', hue='Batch Size', data=df);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kZ2vUYYgclS"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to experiment with batch size on today's assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46cP9Pm_gclS"
      },
      "source": [
        "# Learning Rate (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bna67ADZgclT",
        "toc-hr-collapsed": true
      },
      "source": [
        "## Overview\n",
        "\n",
        "Learning Rate controls the size of the update to our weights that the optimization algorithm makes. VERY IMPORTANT hyperparameter.\n",
        "\n",
        "* Too high of a learning rate causes unstable results\n",
        "* Too Low of a learning rate the model will underfit\n",
        "* Goldy Locks parameters - it needs be \"just right\"\n",
        "* Scale of 0-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsVYOn7bgcle",
        "toc-hr-collapsed": true
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "Same experiment with Batch but different learning rates:\n",
        "* High Learning = .75\n",
        "* Default Learning = .01\n",
        "* Low Learning Rate = .0001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI_H8Em1NOii"
      },
      "source": [
        "### Default Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se8cb_ZUNVtL",
        "outputId": "af597c32-c2f5-4aeb-8eb8-c7c8e7f33386",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bt_default.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.7937999963760376,\n",
              "  0.904699981212616,\n",
              "  0.9191666841506958,\n",
              "  0.9280666708946228,\n",
              "  0.9349166750907898,\n",
              "  0.9405166506767273,\n",
              "  0.9455833435058594,\n",
              "  0.9482499957084656,\n",
              "  0.9519833326339722,\n",
              "  0.9542666673660278,\n",
              "  0.956849992275238,\n",
              "  0.9596499800682068,\n",
              "  0.9609666466712952,\n",
              "  0.9628833532333374,\n",
              "  0.9642666578292847,\n",
              "  0.965499997138977,\n",
              "  0.9674833416938782,\n",
              "  0.9681000113487244,\n",
              "  0.9693833589553833,\n",
              "  0.9703166484832764,\n",
              "  0.9711999893188477,\n",
              "  0.972100019454956,\n",
              "  0.9729166626930237,\n",
              "  0.9741833209991455,\n",
              "  0.9743666648864746],\n",
              " 'loss': [0.7446703910827637,\n",
              "  0.331163227558136,\n",
              "  0.2780238389968872,\n",
              "  0.24772444367408752,\n",
              "  0.2238931506872177,\n",
              "  0.20475436747074127,\n",
              "  0.18895915150642395,\n",
              "  0.17577916383743286,\n",
              "  0.16412533819675446,\n",
              "  0.15443816781044006,\n",
              "  0.1458735167980194,\n",
              "  0.13827677071094513,\n",
              "  0.1315547078847885,\n",
              "  0.12580575048923492,\n",
              "  0.1204494759440422,\n",
              "  0.1161239966750145,\n",
              "  0.11139777302742004,\n",
              "  0.10738791525363922,\n",
              "  0.1035415306687355,\n",
              "  0.10010477155447006,\n",
              "  0.09677629172801971,\n",
              "  0.09343606978654861,\n",
              "  0.09109567850828171,\n",
              "  0.08809161186218262,\n",
              "  0.08576428145170212],\n",
              " 'val_accuracy': [0.8956999778747559,\n",
              "  0.9190999865531921,\n",
              "  0.9291999936103821,\n",
              "  0.9344000220298767,\n",
              "  0.9405999779701233,\n",
              "  0.9434999823570251,\n",
              "  0.9449999928474426,\n",
              "  0.9491999745368958,\n",
              "  0.9524999856948853,\n",
              "  0.9510999917984009,\n",
              "  0.9559000134468079,\n",
              "  0.954200029373169,\n",
              "  0.9581000208854675,\n",
              "  0.9592000246047974,\n",
              "  0.9592999815940857,\n",
              "  0.9610000252723694,\n",
              "  0.9620000123977661,\n",
              "  0.9624000191688538,\n",
              "  0.9621999859809875,\n",
              "  0.9614999890327454,\n",
              "  0.9645000100135803,\n",
              "  0.9632999897003174,\n",
              "  0.9645000100135803,\n",
              "  0.9645000100135803,\n",
              "  0.964900016784668],\n",
              " 'val_loss': [0.3653590679168701,\n",
              "  0.28848397731781006,\n",
              "  0.2520352005958557,\n",
              "  0.23293821513652802,\n",
              "  0.2111477553844452,\n",
              "  0.19368915259838104,\n",
              "  0.1846100240945816,\n",
              "  0.17474696040153503,\n",
              "  0.16291698813438416,\n",
              "  0.15593469142913818,\n",
              "  0.1484941840171814,\n",
              "  0.1495240181684494,\n",
              "  0.1390480399131775,\n",
              "  0.13763724267482758,\n",
              "  0.13450762629508972,\n",
              "  0.13065358996391296,\n",
              "  0.12716931104660034,\n",
              "  0.12359921634197235,\n",
              "  0.12298882752656937,\n",
              "  0.12730607390403748,\n",
              "  0.12019481509923935,\n",
              "  0.117214635014534,\n",
              "  0.11667526513338089,\n",
              "  0.11500465124845505,\n",
              "  0.11626043915748596]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQZ4SZdKNMRO"
      },
      "source": [
        "### High Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny72mU_dNWMR",
        "outputId": "72ba4b21-59a7-4c34-856e-dc38816c016d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = create_model(lr=0.75)\n",
        "\n",
        "lr_high = model.fit(\n",
        "  X_train, y_train,\n",
        "  epochs=25,\n",
        "  batch_size=32,\n",
        "  validation_data=(X_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8175 - accuracy: 0.7239 - val_loss: 0.4750 - val_accuracy: 0.8730\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4965 - accuracy: 0.8549 - val_loss: 0.4026 - val_accuracy: 0.8979\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4202 - accuracy: 0.8885 - val_loss: 0.3523 - val_accuracy: 0.9082\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3997 - accuracy: 0.8991 - val_loss: 0.3497 - val_accuracy: 0.9194\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4267 - accuracy: 0.8891 - val_loss: 0.3771 - val_accuracy: 0.9104\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4132 - accuracy: 0.8970 - val_loss: 0.4916 - val_accuracy: 0.8178\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6383 - accuracy: 0.8087 - val_loss: 0.7437 - val_accuracy: 0.7244\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6197 - accuracy: 0.8140 - val_loss: 0.4619 - val_accuracy: 0.9031\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7385 - accuracy: 0.7603 - val_loss: 0.7843 - val_accuracy: 0.7466\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7868 - accuracy: 0.7272 - val_loss: 1.1361 - val_accuracy: 0.5612\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9794 - accuracy: 0.6009 - val_loss: 0.9991 - val_accuracy: 0.5548\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0733 - accuracy: 0.5589 - val_loss: 1.0218 - val_accuracy: 0.6073\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1214 - accuracy: 0.5292 - val_loss: 1.1864 - val_accuracy: 0.4729\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2248 - accuracy: 0.4630 - val_loss: 1.1941 - val_accuracy: 0.4780\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.4236 - accuracy: 0.3898 - val_loss: 1.6905 - val_accuracy: 0.2675\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.8454 - accuracy: 0.2494 - val_loss: 1.8064 - val_accuracy: 0.2661\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7895 - accuracy: 0.2623 - val_loss: 1.8555 - val_accuracy: 0.2328\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.8302 - accuracy: 0.2490 - val_loss: 1.7982 - val_accuracy: 0.2651\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7584 - accuracy: 0.2828 - val_loss: 1.6128 - val_accuracy: 0.3381\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7695 - accuracy: 0.2707 - val_loss: 1.7755 - val_accuracy: 0.2737\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7772 - accuracy: 0.2580 - val_loss: 1.7612 - val_accuracy: 0.2799\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7600 - accuracy: 0.2620 - val_loss: 1.7819 - val_accuracy: 0.2615\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7532 - accuracy: 0.2576 - val_loss: 1.7738 - val_accuracy: 0.2562\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7724 - accuracy: 0.2581 - val_loss: 1.7876 - val_accuracy: 0.2426\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.7575 - accuracy: 0.2605 - val_loss: 1.8694 - val_accuracy: 0.2563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAqDmTVBNSMR"
      },
      "source": [
        "### Low Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ech1ER64NXBn",
        "outputId": "6748eca6-80aa-48e8-e72e-c5471765512d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = create_model(lr=0.001)\n",
        "\n",
        "lr_low = model.fit(\n",
        "  X_train, y_train,\n",
        "  epochs=25,\n",
        "  batch_size=32,\n",
        "  validation_data=(X_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.9865 - accuracy: 0.4209 - val_loss: 1.5430 - val_accuracy: 0.6906\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.1761 - accuracy: 0.7365 - val_loss: 0.8719 - val_accuracy: 0.7965\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7604 - accuracy: 0.8081 - val_loss: 0.6348 - val_accuracy: 0.8403\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6000 - accuracy: 0.8426 - val_loss: 0.5271 - val_accuracy: 0.8615\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5154 - accuracy: 0.8619 - val_loss: 0.4637 - val_accuracy: 0.8745\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4620 - accuracy: 0.8735 - val_loss: 0.4211 - val_accuracy: 0.8862\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4254 - accuracy: 0.8820 - val_loss: 0.3931 - val_accuracy: 0.8898\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3988 - accuracy: 0.8888 - val_loss: 0.3702 - val_accuracy: 0.8952\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3787 - accuracy: 0.8937 - val_loss: 0.3534 - val_accuracy: 0.8999\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3628 - accuracy: 0.8977 - val_loss: 0.3393 - val_accuracy: 0.9031\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3496 - accuracy: 0.9013 - val_loss: 0.3285 - val_accuracy: 0.9060\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3386 - accuracy: 0.9034 - val_loss: 0.3197 - val_accuracy: 0.9088\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3289 - accuracy: 0.9065 - val_loss: 0.3120 - val_accuracy: 0.9110\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3203 - accuracy: 0.9080 - val_loss: 0.3038 - val_accuracy: 0.9126\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3129 - accuracy: 0.9105 - val_loss: 0.2973 - val_accuracy: 0.9142\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3059 - accuracy: 0.9130 - val_loss: 0.2918 - val_accuracy: 0.9159\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2996 - accuracy: 0.9140 - val_loss: 0.2875 - val_accuracy: 0.9172\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2940 - accuracy: 0.9156 - val_loss: 0.2821 - val_accuracy: 0.9197\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2886 - accuracy: 0.9171 - val_loss: 0.2772 - val_accuracy: 0.9205\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2835 - accuracy: 0.9186 - val_loss: 0.2736 - val_accuracy: 0.9218\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2789 - accuracy: 0.9196 - val_loss: 0.2701 - val_accuracy: 0.9223\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2744 - accuracy: 0.9212 - val_loss: 0.2660 - val_accuracy: 0.9234\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2704 - accuracy: 0.9223 - val_loss: 0.2620 - val_accuracy: 0.9244\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2665 - accuracy: 0.9233 - val_loss: 0.2592 - val_accuracy: 0.9260\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2627 - accuracy: 0.9245 - val_loss: 0.2559 - val_accuracy: 0.9264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZe6DyhANXdU"
      },
      "source": [
        "### Visualization of Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn-BdFdMNph-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb2aiw_Sgcl7"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to experiment with different learning rates today.\n",
        "\n",
        "---"
      ]
    }
  ]
}